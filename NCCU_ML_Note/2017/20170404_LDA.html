<!DOCTYPE html><html><head><meta charset="utf-8"><style>@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }

  a,
  a:visited {
    text-decoration: underline;
  }

  a[href]:after {
    content: " (" attr(href) ")";
  }

  abbr[title]:after {
    content: " (" attr(title) ")";
  }

  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }

  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }

  thead {
    display: table-header-group;
  }

  tr,
  img {
    page-break-inside: avoid;
  }

  img {
    max-width: 100% !important;
  }

  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }

  h2,
  h3 {
    page-break-after: avoid;
  }
}

pre,
code {
  font-family: Menlo, Monaco, "Courier New", monospace;
}

pre {
  padding: .5rem;
  line-height: 1.25;
  overflow-x: scroll;
}

a,
a:visited {
  color: #3498db;
}

a:hover,
a:focus,
a:active {
  color: #2980b9;
}

.modest-no-decoration {
  text-decoration: none;
}

html {
  font-size: 12px;
}

@media screen and (min-width: 32rem) and (max-width: 48rem) {
  html {
    font-size: 15px;
  }
}

@media screen and (min-width: 48rem) {
  html {
    font-size: 16px;
  }
}

body {
  line-height: 1.85;
}

p,
.modest-p {
  font-size: 1rem;
  margin-bottom: 1.3rem;
}

h1,
.modest-h1,
h2,
.modest-h2,
h3,
.modest-h3,
h4,
.modest-h4 {
  margin: 1.414rem 0 .5rem;
  font-weight: inherit;
  line-height: 1.42;
}

h1,
.modest-h1 {
  margin-top: 0;
  font-size: 3.998rem;
}

h2,
.modest-h2 {
  font-size: 2.261rem;
  /*font-size: 2.827rem; */
}

h3,
.modest-h3 {
  font-size: 1.599rem;
  /*font-size: 1.999rem;*/
}

h4,
.modest-h4 {
  font-size: 1.272rem;
  /*font-size: 1.414rem;*/
}

h5,
.modest-h5 {
  font-size: 1.121rem;
}

h6,
.modest-h6 {
  font-size: .88rem;
}

small,
.modest-small {
  font-size: .3em;
}

/* https://github.com/mrmrs/fluidity */

img,
canvas,
iframe,
video,
svg,
select,
textarea {
  max-width: 100%;
}

@import url(http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,300italic,700);

@import url(http://fonts.googleapis.com/css?family=Arimo:700,700italic);

html {
  font-size: 18px;
  max-width: 100%;
}

body {
  color: #444;
  font-family: 'Open Sans Condensed', sans-serif;
  font-weight: 300;
  margin: 0 auto;
  max-width: 48rem;
  line-height: 1.45;
  padding: .25rem;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  font-family: Arimo, Helvetica, sans-serif;
}

h1{
  border-bottom: 2px solid #fafafa;
  margin-bottom: 1.15rem;
  padding-bottom: .5rem;
  text-align: center;
}

h2,
h3 {
  border-bottom: 2px solid #fafafa;
  margin-bottom: 1.15rem;
  padding-bottom: .5rem;
  text-align: left;
}


blockquote {
  border-left: 8px solid #fafafa;
  padding: 1rem;
}

pre,
code {
  background-color: #fafafa;
}
</style><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>20170404_LDA</title></head><body><article class="markdown-body"><h1 id="fisher-approach"><a name="user-content-fisher-approach" href="#fisher-approach" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Fisher Approach</h1>
<h2 id="goals"><a name="user-content-goals" href="#goals" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Goals</h2>
<ul>
<li>Taking linear combinations a&rsquo;X of the attributes in T so that different classes can be best distinguished.</li>
<li>$max \frac{a&rsquo;Ba}{a&rsquo;Wa}$ </li>
</ul>
<h2 id="steps"><a name="user-content-steps" href="#steps" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Steps</h2>
<ul>
<li>計算每一組k的 $x_k$ </li>
<li>計算不分組的 $\bar{x}$</li>
<li>計算 between-group variance matrix </li>
<li>計算 within-group variance matrix</li>
<li>排序$W^{-1}B$ eigenvalue，取 r eigenvector, $p$ X  $r$ dimension matrix $W^{-1}B$<ul>
<li>所有可得解為 min(K-1, p) = r</li>
</ul>
</li>
</ul>
<h2 id="how-to-classify-new-object"><a name="user-content-how-to-classify-new-object" href="#how-to-classify-new-object" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>How to classify new object ?</h2>
<p><center><br />
    <img src="/Users/sheng/Documents/NCCU/ML/NCCU_ML_Note/2017/img/img3.jpg" style="width: 40%; height: 40%" />​<br />
</center></p>
<p>在Step5得到的 Linear Discriminants（LD, 即 $W^{-1}B$的Eigenvector）可以看作一種投影(線性組合)。如果r = 2的情況，會將新的資料投影到LD Space。比較新資料在LD Space中與k個類別中心的距離，類別預測的判定則基於最短距離。</p>
<p>實際上我們可以投影到的 r 可以選擇在 ≤ min(K-1, p)</p>
<h1 id="bayesian-approach"><a name="user-content-bayesian-approach" href="#bayesian-approach" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Bayesian Approach</h1>
<h2 id="goals_1"><a name="user-content-goals_1" href="#goals_1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Goals</h2>
<ul>
<li>$P_r(Y=k | X=x) = \frac{\pi_k   f_k (x)}{\sum_{l=1}^{K} \pi_l   f_l (x)}$</li>
<li>To estimate  $\pi_k$ and $f_k (x)$ from  $\frac{\pi_k   f_k (x)}{\sum_{l=1}^{K} \pi_l   f_l (x)}$</li>
<li>Assume Normal Distribution &amp; Common Variance on $f_x(x)$, if Common Variance is violated, then uses QDA.</li>
</ul>
<h2 id="how-to-classify-new-object_1"><a name="user-content-how-to-classify-new-object_1" href="#how-to-classify-new-object_1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>How to classify new object ?</h2>
<h4 id="discriminant-functions"><a name="user-content-discriminant-functions" href="#discriminant-functions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Discriminant Functions :</h4>
<p>$\delta_k(x) = x^T\sum^{-1}\mu_k - \frac{1}{2}\mu_k^T\sum^{-1}\mu_{k} + log(\pi_k)$</p>
<p>歸類給 K 當 $\delta_k(x)$   </p>
<h4 id="boundary-decision"><a name="user-content-boundary-decision" href="#boundary-decision" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Boundary Decision :</h4>
<p>Boundary發生在 $\delta_i(x)$ = $\delta_j(x)$ , for all $i, j \in k$</p>
<h1 id="questions"><a name="user-content-questions" href="#questions" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Questions</h1>
<blockquote>
<ul>
<li>
<p>今天花了一個小時了解 Fisher（線代解） &amp; Bayesian Approach（課本解） 的差異。<br />
但還是無法抓到重點。希望LDA或是其他夥伴可以幫忙理解看看XD<br />
<a href="http://stats.stackexchange.com/questions/87975/bayesian-and-fishers-approaches-to-linear-discriminant-analysis">http://stats.stackexchange.com/questions/87975/bayesian-and-fishers-approaches-to-linear-discriminant-analysis</a><br />
整理一些我目前了解的片面結論：<br />
1. Bayesian Assume normal &amp; common variance. 若違反variance的假設 就變成QDA去解<br />
2. Fisher 有 Dimension Reduction 的效果，可以降到 min( 組別數-1, 變數個數）以下的維度<br />
3. Why min(k-1, p)?</p>
</li>
<li>
<p>PCA vs LDA ? <br />
<strong>相似之處</strong> : 兩者都是用線性組合技巧<br />
PCA : unsupervised, 忽略class labels, goal : 找到最大變異的方向<br />
LDA : supervised, goal : 找到切割越好的軸，投影上去<br />
<img src="http://sebastianraschka.com/images/blog/2014/linear-discriminant-analysis/lda_1.png" style="width: 40%; height: 40%"/>​<br />
<a href="http://sebastianraschka.com/Articles/2014_python_lda.html#a-comparison-of-pca-and-lda">PCA vs LDA 參考</a></p>
</li>
<li>
<p>Logistic Regression vs LDA</p>
</li>
<li>
<p>Multiple variables, how to calculate between-group variance matrix, and within- group Variance?</p>
</li>
<li>
<p>how to find optimal values of a(linear combinations of variables)</p>
</li>
<li>
<p>高維度計算效能？</p>
</li>
<li>
<p>Outlier影響嚴不嚴重</p>
</li>
</ul>
</blockquote>
<h1 id="reference"><a name="user-content-reference" href="#reference" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Reference</h1>
<ul>
<li><a href="http://stats.stackexchange.com/questions/123490/what-is-the-correct-formula-for-between-class-scatter-matrix-in-lda">What is the correct formula for between-class scatter matrix in LDA?</a></li>
</ul>
<h1 id="r-labs"><a name="user-content-r-labs" href="#r-labs" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>R labs</h1>
<p><img src="" alt=""></p></article></body></html>